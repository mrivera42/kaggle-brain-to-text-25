{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "426381d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60cb2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.11/data_train.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8bf5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def load_h5py_file(file_path):\n",
    "    data = {\n",
    "        'neural_features': [],\n",
    "        'n_time_steps': [],\n",
    "        'seq_class_ids': [],\n",
    "        'seq_len': [],\n",
    "        'transcriptions': [],\n",
    "        'sentence_label': [],\n",
    "        'session': [],\n",
    "        'block_num': [],\n",
    "        'trial_num': [],\n",
    "    }\n",
    "    # Open the hdf5 file for that day\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "\n",
    "        keys = list(f.keys())\n",
    "\n",
    "        # For each trial in the selected trials in that day\n",
    "        for key in keys:\n",
    "            g = f[key]\n",
    "\n",
    "            neural_features = g['input_features'][:]\n",
    "            n_time_steps = g.attrs['n_time_steps']\n",
    "            seq_class_ids = g['seq_class_ids'][:] if 'seq_class_ids' in g else None\n",
    "            seq_len = g.attrs['seq_len'] if 'seq_len' in g.attrs else None\n",
    "            transcription = g['transcription'][:] if 'transcription' in g else None\n",
    "            sentence_label = g.attrs['sentence_label'][:] if 'sentence_label' in g.attrs else None\n",
    "            session = g.attrs['session']\n",
    "            block_num = g.attrs['block_num']\n",
    "            trial_num = g.attrs['trial_num']\n",
    "\n",
    "            data['neural_features'].append(neural_features)\n",
    "            data['n_time_steps'].append(n_time_steps)\n",
    "            data['seq_class_ids'].append(seq_class_ids)\n",
    "            data['seq_len'].append(seq_len)\n",
    "            data['transcriptions'].append(transcription)\n",
    "            data['sentence_label'].append(sentence_label)\n",
    "            data['session'].append(session)\n",
    "            data['block_num'].append(block_num)\n",
    "            data['trial_num'].append(trial_num)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae7ef628",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_h5py_file(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b50360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neural_features',\n",
       " 'n_time_steps',\n",
       " 'seq_class_ids',\n",
       " 'seq_len',\n",
       " 'transcriptions',\n",
       " 'sentence_label',\n",
       " 'session',\n",
       " 'block_num',\n",
       " 'trial_num']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7502829",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File(filepath, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f350a651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trial_0000',\n",
       " 'trial_0001',\n",
       " 'trial_0002',\n",
       " 'trial_0003',\n",
       " 'trial_0004',\n",
       " 'trial_0005',\n",
       " 'trial_0006',\n",
       " 'trial_0007',\n",
       " 'trial_0008',\n",
       " 'trial_0009',\n",
       " 'trial_0010',\n",
       " 'trial_0011',\n",
       " 'trial_0012',\n",
       " 'trial_0013',\n",
       " 'trial_0014',\n",
       " 'trial_0015',\n",
       " 'trial_0016',\n",
       " 'trial_0017',\n",
       " 'trial_0018',\n",
       " 'trial_0019',\n",
       " 'trial_0020',\n",
       " 'trial_0021',\n",
       " 'trial_0022',\n",
       " 'trial_0023',\n",
       " 'trial_0024',\n",
       " 'trial_0025',\n",
       " 'trial_0026',\n",
       " 'trial_0027',\n",
       " 'trial_0028',\n",
       " 'trial_0029',\n",
       " 'trial_0030',\n",
       " 'trial_0031',\n",
       " 'trial_0032',\n",
       " 'trial_0033',\n",
       " 'trial_0034',\n",
       " 'trial_0035',\n",
       " 'trial_0036',\n",
       " 'trial_0037',\n",
       " 'trial_0038',\n",
       " 'trial_0039',\n",
       " 'trial_0040',\n",
       " 'trial_0041',\n",
       " 'trial_0042',\n",
       " 'trial_0043',\n",
       " 'trial_0044',\n",
       " 'trial_0045',\n",
       " 'trial_0046',\n",
       " 'trial_0047',\n",
       " 'trial_0048',\n",
       " 'trial_0049',\n",
       " 'trial_0050',\n",
       " 'trial_0051',\n",
       " 'trial_0052',\n",
       " 'trial_0053',\n",
       " 'trial_0054',\n",
       " 'trial_0055',\n",
       " 'trial_0056',\n",
       " 'trial_0057',\n",
       " 'trial_0058',\n",
       " 'trial_0059',\n",
       " 'trial_0060',\n",
       " 'trial_0061',\n",
       " 'trial_0062',\n",
       " 'trial_0063',\n",
       " 'trial_0064',\n",
       " 'trial_0065',\n",
       " 'trial_0066',\n",
       " 'trial_0067',\n",
       " 'trial_0068',\n",
       " 'trial_0069',\n",
       " 'trial_0070',\n",
       " 'trial_0071',\n",
       " 'trial_0072',\n",
       " 'trial_0073',\n",
       " 'trial_0074',\n",
       " 'trial_0075',\n",
       " 'trial_0076',\n",
       " 'trial_0077',\n",
       " 'trial_0078',\n",
       " 'trial_0079',\n",
       " 'trial_0080',\n",
       " 'trial_0081',\n",
       " 'trial_0082',\n",
       " 'trial_0083',\n",
       " 'trial_0084',\n",
       " 'trial_0085',\n",
       " 'trial_0086',\n",
       " 'trial_0087',\n",
       " 'trial_0088',\n",
       " 'trial_0089',\n",
       " 'trial_0090',\n",
       " 'trial_0091',\n",
       " 'trial_0092',\n",
       " 'trial_0093',\n",
       " 'trial_0094',\n",
       " 'trial_0095',\n",
       " 'trial_0096',\n",
       " 'trial_0097',\n",
       " 'trial_0098',\n",
       " 'trial_0099',\n",
       " 'trial_0100',\n",
       " 'trial_0101',\n",
       " 'trial_0102',\n",
       " 'trial_0103',\n",
       " 'trial_0104',\n",
       " 'trial_0105',\n",
       " 'trial_0106',\n",
       " 'trial_0107',\n",
       " 'trial_0108',\n",
       " 'trial_0109',\n",
       " 'trial_0110',\n",
       " 'trial_0111',\n",
       " 'trial_0112',\n",
       " 'trial_0113',\n",
       " 'trial_0114',\n",
       " 'trial_0115',\n",
       " 'trial_0116',\n",
       " 'trial_0117',\n",
       " 'trial_0118',\n",
       " 'trial_0119',\n",
       " 'trial_0120',\n",
       " 'trial_0121',\n",
       " 'trial_0122',\n",
       " 'trial_0123',\n",
       " 'trial_0124',\n",
       " 'trial_0125',\n",
       " 'trial_0126',\n",
       " 'trial_0127',\n",
       " 'trial_0128',\n",
       " 'trial_0129',\n",
       " 'trial_0130',\n",
       " 'trial_0131',\n",
       " 'trial_0132',\n",
       " 'trial_0133',\n",
       " 'trial_0134',\n",
       " 'trial_0135',\n",
       " 'trial_0136',\n",
       " 'trial_0137',\n",
       " 'trial_0138',\n",
       " 'trial_0139',\n",
       " 'trial_0140',\n",
       " 'trial_0141',\n",
       " 'trial_0142',\n",
       " 'trial_0143',\n",
       " 'trial_0144',\n",
       " 'trial_0145',\n",
       " 'trial_0146',\n",
       " 'trial_0147',\n",
       " 'trial_0148',\n",
       " 'trial_0149',\n",
       " 'trial_0150',\n",
       " 'trial_0151',\n",
       " 'trial_0152',\n",
       " 'trial_0153',\n",
       " 'trial_0154',\n",
       " 'trial_0155',\n",
       " 'trial_0156',\n",
       " 'trial_0157',\n",
       " 'trial_0158',\n",
       " 'trial_0159',\n",
       " 'trial_0160',\n",
       " 'trial_0161',\n",
       " 'trial_0162',\n",
       " 'trial_0163',\n",
       " 'trial_0164',\n",
       " 'trial_0165',\n",
       " 'trial_0166',\n",
       " 'trial_0167',\n",
       " 'trial_0168',\n",
       " 'trial_0169',\n",
       " 'trial_0170',\n",
       " 'trial_0171',\n",
       " 'trial_0172',\n",
       " 'trial_0173',\n",
       " 'trial_0174',\n",
       " 'trial_0175',\n",
       " 'trial_0176',\n",
       " 'trial_0177',\n",
       " 'trial_0178',\n",
       " 'trial_0179',\n",
       " 'trial_0180',\n",
       " 'trial_0181',\n",
       " 'trial_0182',\n",
       " 'trial_0183',\n",
       " 'trial_0184',\n",
       " 'trial_0185',\n",
       " 'trial_0186',\n",
       " 'trial_0187',\n",
       " 'trial_0188',\n",
       " 'trial_0189',\n",
       " 'trial_0190',\n",
       " 'trial_0191',\n",
       " 'trial_0192',\n",
       " 'trial_0193',\n",
       " 'trial_0194',\n",
       " 'trial_0195',\n",
       " 'trial_0196',\n",
       " 'trial_0197',\n",
       " 'trial_0198',\n",
       " 'trial_0199',\n",
       " 'trial_0200',\n",
       " 'trial_0201',\n",
       " 'trial_0202',\n",
       " 'trial_0203',\n",
       " 'trial_0204',\n",
       " 'trial_0205',\n",
       " 'trial_0206',\n",
       " 'trial_0207',\n",
       " 'trial_0208',\n",
       " 'trial_0209',\n",
       " 'trial_0210',\n",
       " 'trial_0211',\n",
       " 'trial_0212',\n",
       " 'trial_0213',\n",
       " 'trial_0214',\n",
       " 'trial_0215',\n",
       " 'trial_0216',\n",
       " 'trial_0217',\n",
       " 'trial_0218',\n",
       " 'trial_0219',\n",
       " 'trial_0220',\n",
       " 'trial_0221',\n",
       " 'trial_0222',\n",
       " 'trial_0223',\n",
       " 'trial_0224',\n",
       " 'trial_0225',\n",
       " 'trial_0226',\n",
       " 'trial_0227',\n",
       " 'trial_0228',\n",
       " 'trial_0229',\n",
       " 'trial_0230',\n",
       " 'trial_0231',\n",
       " 'trial_0232',\n",
       " 'trial_0233',\n",
       " 'trial_0234',\n",
       " 'trial_0235',\n",
       " 'trial_0236',\n",
       " 'trial_0237',\n",
       " 'trial_0238',\n",
       " 'trial_0239',\n",
       " 'trial_0240',\n",
       " 'trial_0241',\n",
       " 'trial_0242',\n",
       " 'trial_0243',\n",
       " 'trial_0244',\n",
       " 'trial_0245',\n",
       " 'trial_0246',\n",
       " 'trial_0247',\n",
       " 'trial_0248',\n",
       " 'trial_0249',\n",
       " 'trial_0250',\n",
       " 'trial_0251',\n",
       " 'trial_0252',\n",
       " 'trial_0253',\n",
       " 'trial_0254',\n",
       " 'trial_0255',\n",
       " 'trial_0256',\n",
       " 'trial_0257',\n",
       " 'trial_0258',\n",
       " 'trial_0259',\n",
       " 'trial_0260',\n",
       " 'trial_0261',\n",
       " 'trial_0262',\n",
       " 'trial_0263',\n",
       " 'trial_0264',\n",
       " 'trial_0265',\n",
       " 'trial_0266',\n",
       " 'trial_0267',\n",
       " 'trial_0268',\n",
       " 'trial_0269',\n",
       " 'trial_0270',\n",
       " 'trial_0271',\n",
       " 'trial_0272',\n",
       " 'trial_0273',\n",
       " 'trial_0274',\n",
       " 'trial_0275',\n",
       " 'trial_0276',\n",
       " 'trial_0277',\n",
       " 'trial_0278',\n",
       " 'trial_0279',\n",
       " 'trial_0280',\n",
       " 'trial_0281',\n",
       " 'trial_0282',\n",
       " 'trial_0283',\n",
       " 'trial_0284',\n",
       " 'trial_0285',\n",
       " 'trial_0286',\n",
       " 'trial_0287']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(f.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43759287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.21 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.28 ['data_train.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.28 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.30 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.13 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.24 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.10 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.08 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.27 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.03 ['data_train.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.29 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.06 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.01 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.17 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.25 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.17 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.13 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.04 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.15 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.03 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.03 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.15 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.07.19 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.03 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.17 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.14 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.03.08 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.26 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.20 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.05.10 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.06.14 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.11.19 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.18 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2025.04.13 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2025.03.16 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.08 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2025.01.12 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.04.25 ['data_train.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.29 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.22 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.08.11 ['data_train.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2024.02.25 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.12.10 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.10.20 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n",
      "t15_copyTask_neuralData/hdf5_data_final/t15.2023.09.01 ['data_test.hdf5', 'data_train.hdf5', 'data_val.hdf5']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "for folder, _, files in os.walk('t15_copyTask_neuralData/hdf5_data_final'):\n",
    "    \n",
    "    if 'data_train.hdf5' in files:\n",
    "\n",
    "        print(folder, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2312d2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "class NeuralDataset(torch.utils.data.Dataset): \n",
    "\n",
    "    def __init__(self, dir):\n",
    "        \n",
    "        self.data = {\n",
    "            'neural_features': [],\n",
    "            'n_time_steps': [],\n",
    "            'seq_class_ids': [], \n",
    "            'seq_len': [], \n",
    "            'transcription': [], \n",
    "            'sentence_label': [], \n",
    "            'session': [], \n",
    "            'block_num': [], \n",
    "            'trial_num': []\n",
    "        }\n",
    "\n",
    "        for folder, __, files in os.walk(dir): \n",
    "\n",
    "            if 'data_train.hdf5' in files: \n",
    "\n",
    "                # load file \n",
    "                f = h5py.File(os.path.join(folder, 'data_train.hdf5'))\n",
    "\n",
    "                # loop through trials \n",
    "                for i in list(f.keys()): \n",
    "\n",
    "                    trial = f[i]\n",
    "\n",
    "                    neural_features = trial['input_features'][:]\n",
    "                    n_time_steps = trial.attrs['n_time_steps']\n",
    "                    seq_class_ids = trial['seq_class_ids'][:] if 'seq_class_ids' in trial else None\n",
    "                    seq_len = trial.attrs['seq_len'] if 'seq_len' in trial.attrs else None\n",
    "                    transcription = trial['transcription'][:] if 'transcription' in trial else None\n",
    "                    sentence_label = trial.attrs['sentence_label'][:] if 'sentence_label' in trial.attrs else None\n",
    "                    session = trial.attrs['session']\n",
    "                    block_num = trial.attrs['block_num']\n",
    "                    trial_num = trial.attrs['trial_num']\n",
    "\n",
    "                    # append trial features to data list \n",
    "                    self.data['neural_features'].append(neural_features)\n",
    "                    self.data['n_time_steps'].append(n_time_steps)\n",
    "                    self.data['seq_class_ids'].append(seq_class_ids)\n",
    "                    self.data['seq_len'].append(seq_len)\n",
    "                    self.data['transcription'].append(transcription)\n",
    "                    self.data['sentence_label'].append(sentence_label)\n",
    "                    self.data['session'].append(session)\n",
    "                    self.data['block_num'].append(block_num)\n",
    "                    self.data['trial_num'].append(trial_num)\n",
    "\n",
    "    def __len__(self): \n",
    "\n",
    "        return len(self.data['neural_features'])\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "\n",
    "        return {\n",
    "            'neural_features': torch.tensor(self.data['neural_features'][idx]),\n",
    "            'n_time_steps': torch.tensor(self.data['n_time_steps'][idx]),\n",
    "            'seq_class_ids': torch.tensor(self.data['seq_class_ids'][idx]),\n",
    "            'seq_len': torch.tensor(self.data['seq_len'][idx]),\n",
    "            'transcription': self.data['transcription'][idx],\n",
    "            'sentence_label': self.data['sentence_label'][idx],\n",
    "            'session': self.data['session'][idx],\n",
    "            'block_num': self.data['block_num'][idx],\n",
    "            'trial_num': self.data['trial_num'][idx]\n",
    "        }\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a999eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "brainDataset = NeuralDataset('t15_copyTask_neuralData/hdf5_data_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22995e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([517, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brainDataset.__getitem__(4)['neural_features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55ad6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader \n",
    "from torch.nn.utils.rnn import pad_sequence \n",
    "import numpy as np\n",
    "\n",
    "def collate_fn(batch):\n",
    "\n",
    "    # gather all the variable length items (neural_features, seq_labels) from the batch into separate python lists first so we can find the max length of each group and pad each group together\n",
    "\n",
    "    neural_features = [i['neural_features'] for i in batch]\n",
    "    seq_class_ids = [i['seq_class_ids'] for i in batch]\n",
    "    n_time_steps = [i['n_time_steps'] for i in batch]\n",
    "    seq_len = [i['seq_len'] for i in batch] \n",
    "    transcription = [i['transcription'] for i in batch]\n",
    "    sentence_label = [i['sentence_label'] for i in batch]\n",
    "    session = [i['session'] for i in batch]\n",
    "    block_num = [i['block_num'] for i in batch]\n",
    "    trial_num = [i['trial_num'] for i in batch]\n",
    "    # neural_lengths = [len(i) for i in neural_features]\n",
    "    # seq_class_lengths = [len(i) for i in seq_class_ids]\n",
    "\n",
    "    # max_neural_idx = np.argmax(neural_lengths)\n",
    "    # max_seq_class_idx = np.argmax(seq_class_lengths)\n",
    "\n",
    "    # max_neural_len = neural_lengths[max_neural_idx]\n",
    "    # max_seq_len = seq_class_lengths[max_seq_class_idx]\n",
    "\n",
    "    neural_features_padded = pad_sequence(neural_features, batch_first=True, padding_value=0)\n",
    "    seq_class_ids_padded = pad_sequence(seq_class_ids, batch_first=True, padding_value=0)\n",
    "\n",
    "    return {\n",
    "        'neural_features': neural_features_padded,\n",
    "        'seq_class_ids': seq_class_ids_padded,\n",
    "        'n_time_steps': n_time_steps,\n",
    "        'seq_len': seq_len,\n",
    "        'transcription': transcription,\n",
    "        'sentence_label': sentence_label,\n",
    "        'session': session,\n",
    "        'block_num': block_num,\n",
    "        'trial_num': trial_num\n",
    "    }\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e383f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "trainLoader = DataLoader(brainDataset, batch_size=4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a130bbcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neural_features': tensor([[[-0.3003,  0.4238, -0.7064,  ..., -0.3712, -0.3446,  0.2089],\n",
       "          [-0.3003, -0.7120, -0.7064,  ...,  3.3335,  0.9658, -0.3117],\n",
       "          [-0.3003, -0.7120, -0.7064,  ...,  0.9588, -1.1609,  1.6493],\n",
       "          ...,\n",
       "          [-0.3003, -0.7120,  3.0599,  ..., -0.8327,  1.0939, -0.1702],\n",
       "          [-0.3003, -0.7120,  0.5490,  ..., -0.9575, -0.3140, -1.1289],\n",
       "          [-0.3003, -0.7120, -0.7064,  ...,  0.0992, -1.4184,  0.5835]],\n",
       " \n",
       "         [[-0.2886, -0.6776,  0.6852,  ..., -0.8004,  0.0621,  0.5236],\n",
       "          [-0.2886,  0.5355,  3.3447,  ...,  1.2232,  0.5247, -0.9197],\n",
       "          [-0.2886,  0.5355, -0.6445,  ..., -0.2722, -0.6868, -0.5445],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.2746,  0.5775, -0.6807,  ...,  0.9687, -0.0815,  0.6085],\n",
       "          [-0.2746, -0.6481,  1.8365,  ..., -0.5639,  0.7008,  1.1431],\n",
       "          [-0.2746, -0.6481, -0.6807,  ..., -0.7827,  0.0639, -1.2594],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.2716, -0.6396, -0.6780,  ..., -0.8097, -0.5040, -1.2761],\n",
       "          [-0.2716, -0.6396, -0.6780,  ...,  0.3748,  0.7030,  0.1488],\n",
       "          [-0.2716, -0.6396, -0.6780,  ..., -0.7618, -0.9032, -0.2469],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]),\n",
       " 'seq_class_ids': tensor([[ 3, 40,  7,  ...,  0,  0,  0],\n",
       "         [16,  5, 40,  ...,  0,  0,  0],\n",
       "         [22,  6, 23,  ...,  0,  0,  0],\n",
       "         [ 6, 22, 40,  ...,  0,  0,  0]], dtype=torch.int32),\n",
       " 'n_time_steps': [tensor(654), tensor(524), tensor(488), tensor(458)],\n",
       " 'seq_len': [tensor(34), tensor(21), tensor(19), tensor(22)],\n",
       " 'transcription': [array([ 65,  32,  98, 117, 110,  99, 104,  32, 111, 102,  32, 112, 115,\n",
       "         121,  99, 104, 105,  97, 116, 114, 105, 115, 116, 115,  32,  97,\n",
       "         114, 101,  32, 104,  97, 110, 103, 105, 110, 103,  32, 111, 117,\n",
       "         116,  46,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0], dtype=int32),\n",
       "  array([ 72, 111, 119,  32, 100, 105, 100,  32, 121, 111, 117,  32, 106,\n",
       "         111, 105, 110,  32, 116, 104, 101,  32, 102, 105, 103, 104, 116,\n",
       "          63,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0], dtype=int32),\n",
       "  array([ 77, 105, 110, 101,  32,  97, 114, 101,  32, 109, 105, 120, 101,\n",
       "         100,  32, 117, 112,  32, 116, 111, 111,  46,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0], dtype=int32),\n",
       "  array([ 73,  39, 109,  32,  97, 110,  32, 101, 110, 103, 105, 110, 101,\n",
       "         101, 114,  32,  98, 121,  32, 116, 114,  97, 100, 101,  46,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0], dtype=int32)],\n",
       " 'sentence_label': ['A bunch of psychiatrists are hanging out.',\n",
       "  'How did you join the fight?',\n",
       "  'Mine are mixed up too.',\n",
       "  \"I'm an engineer by trade.\"],\n",
       " 'session': ['t15.2024.07.21',\n",
       "  't15.2024.07.21',\n",
       "  't15.2024.07.21',\n",
       "  't15.2024.07.21'],\n",
       " 'block_num': [np.int64(1), np.int64(1), np.int64(1), np.int64(1)],\n",
       " 'trial_num': [np.int64(0), np.int64(1), np.int64(2), np.int64(3)]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(trainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03687bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOGIT_TO_PHONEME = [\n",
    "'BLANK',    # \"BLANK\" = CTC blank symbol\n",
    "'AA', 'AE', 'AH', 'AO', 'AW',\n",
    "'AY', 'B', 'CH', 'D', 'DH',\n",
    "'EH', 'ER', 'EY', 'F', 'G',\n",
    "'HH', 'IH', 'IY', 'JH', 'K',\n",
    "'L', 'M', 'N', 'NG', 'OW',\n",
    "'OY', 'P', 'R', 'S', 'SH',\n",
    "'T', 'TH', 'UH', 'UW', 'V',\n",
    "'W', 'Y', 'Z', 'ZH',\n",
    "' | ',    # \"|\" = silence token\n",
    "] \n",
    "\n",
    "len(LOGIT_TO_PHONEME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69b1d33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b22c4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BaselineLSTM(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # input (B x T x 512) --> output (B x T x 41)\n",
    "\n",
    "        self.rnn = torch.nn.LSTM(input_size=512,hidden_size=100, num_layers=5)\n",
    "        self.proj = torch.nn.Linear(in_features=720, out_features=41)\n",
    "\n",
    "\n",
    "    def forward(self, x): \n",
    "\n",
    "        x = self.rnn(x)\n",
    "        x = F.softmax(self.proj(x))\n",
    "\n",
    "        return x \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "602ffb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineLSTM().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d1b2915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaselineLSTM(\n",
      "  (rnn): LSTM(512, 100, num_layers=5)\n",
      "  (proj): Linear(in_features=720, out_features=41, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6899ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training loop \n",
    "import torch.optim as optim \n",
    "\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=1e-5)\n",
    "loss_fn = torch.nn.CTCLoss()\n",
    "num_epochs = 10\n",
    "\n",
    "epoch_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    \n",
    "    train_loss = 0\n",
    "    num_batches = len(trainLoader)\n",
    "    for i, (inputs, targets) in enumerate(trainLoader):\n",
    "\n",
    "        # place tensors on device\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # zero optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward \n",
    "        output = model.forward(inputs)\n",
    "\n",
    "        # compute loss \n",
    "        loss = loss_fn(output, targets)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # backprop \n",
    "        loss.backwards()\n",
    "\n",
    "        # update weights \n",
    "        optimizer.step()\n",
    "    \n",
    "    train_loss /= num_batches \n",
    "    print(f'Epoch {epoch} loss: {train_loss}')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle-brain-to-text-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
